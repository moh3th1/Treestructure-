{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  GRAPH CODE\n",
    "# ============\n",
    "\n",
    "# Import Tensorflow and Numpy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# ======================\n",
    "# Define the Graph\n",
    "# ======================\n",
    "\n",
    "# Define the Placeholders\n",
    "data = tf.placeholder(\"float\", [10, 10], name=\"data\")\n",
    "Task_1_labels = tf.placeholder(\"float\", [10, 20], name=\"Task_1_labels\")\n",
    "Task_2_labels = tf.placeholder(\"float\", [10, 20], name=\"Task_2_labels\")\n",
    "Task_3_labels = tf.placeholder(\"float\", [10, 20], name=\"Task_3_labels\")\n",
    "\n",
    "# Define the weights for the layers\n",
    "\n",
    "initial_shared_layer_1_weights = np.random.random((10, 20))\n",
    "initial_shared_layer_11_weights = np.random.random((20, 20))\n",
    "\n",
    "initial_Task_1_layer_weights = np.random.rand(20,20)\n",
    "initial_Task_2_layer_weights = np.random.rand(20,20)\n",
    "initial_Task_3_layer_weights = np.random.rand(20,20)\n",
    "\n",
    "\n",
    "shared_layer_1_weights  = tf.Variable(initial_shared_layer_1_weights, name=\"share_1_W\", dtype=\"float32\")\n",
    "shared_layer_11_weights = tf.Variable(initial_shared_layer_11_weights, name=\"share_11_W\", dtype=\"float32\")\n",
    "\n",
    "Task_1_layer_weights = tf.Variable(initial_Task_1_layer_weights, name=\"share_Task1\", dtype=\"float32\")\n",
    "Task_2_layer_weights = tf.Variable(initial_Task_2_layer_weights, name=\"share_Task2\", dtype=\"float32\")\n",
    "Task_3_layer_weights = tf.Variable(initial_Task_3_layer_weights, name=\"share_Task3\", dtype=\"float32\")\n",
    "\n",
    "# Construct the Layers with RELU Activations\n",
    "shared_1_layer = tf.nn.relu(tf.matmul(data,shared_layer_1_weights))\n",
    "shared_11_layer = tf.nn.relu(tf.matmul(shared_layer_1_weights,shared_layer_11_weights))\n",
    "\n",
    "Task_1_layer = tf.nn.relu(tf.matmul(shared_11_layer,Task_1_layer_weights))\n",
    "Task_2_layer = tf.nn.relu(tf.matmul(shared_11_layer,Task_2_layer_weights))\n",
    "Task_3_layer = tf.nn.relu(tf.matmul(shared_1_layer,Task_3_layer_weights))\n",
    "# Calculate Loss\n",
    "Task_1_Loss = tf.nn.l2_loss(Task_1_labels-Task_1_layer)\n",
    "Task_2_Loss = tf.nn.l2_loss(Task_2_labels-Task_2_layer)\n",
    "Task_3_Loss = tf.nn.l2_loss(Task_3_labels-Task_3_layer)\n",
    "# optimisers\n",
    "Task_1_op = tf.train.AdamOptimizer().minimize(Task_1_Loss)\n",
    "Task_2_op = tf.train.AdamOptimizer().minimize(Task_2_Loss)\n",
    "Task_3_op = tf.train.AdamOptimizer().minimize(Task_3_Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task_1_loss 203691.0\n",
      "Task_2_loss 202968.0\n",
      "Task_2_loss 203329.0\n",
      "Task_1_loss 198975.0\n",
      "Task_2_loss 197969.0\n",
      "Task_1_loss 194351.0\n",
      "Task_1_loss 190712.0\n",
      "Task_1_loss 185189.0\n",
      "Task_2_loss 189327.0\n",
      "Task_1_loss 181382.0\n",
      "Task_2_loss 184214.0\n",
      "Task_2_loss 186653.0\n",
      "Task_2_loss 176426.0\n",
      "Task_1_loss 169265.0\n",
      "Task_2_loss 171060.0\n",
      "Task_2_loss 166706.0\n",
      "Task_1_loss 168385.0\n",
      "Task_2_loss 163231.0\n",
      "Task_1_loss 161999.0\n",
      "Task_2_loss 157710.0\n",
      "Task_2_loss 151716.0\n",
      "Task_2_loss 153584.0\n",
      "Task_1_loss 149056.0\n",
      "Task_2_loss 148108.0\n",
      "Task_2_loss 148099.0\n",
      "Task_1_loss 146874.0\n",
      "Task_1_loss 141324.0\n",
      "Task_1_loss 141727.0\n",
      "Task_1_loss 139978.0\n",
      "Task_2_loss 140045.0\n",
      "Task_1_loss 134834.0\n",
      "Task_1_loss 132304.0\n",
      "Task_1_loss 130293.0\n",
      "Task_1_loss 127121.0\n",
      "Task_1_loss 127291.0\n",
      "Task_1_loss 121998.0\n",
      "Task_1_loss 118809.0\n",
      "Task_1_loss 119007.0\n",
      "Task_2_loss 123041.0\n",
      "Task_1_loss 114115.0\n",
      "Task_2_loss 117827.0\n",
      "Task_2_loss 116549.0\n",
      "Task_2_loss 115507.0\n",
      "Task_1_loss 109445.0\n",
      "Task_1_loss 110479.0\n",
      "Task_1_loss 104841.0\n",
      "Task_2_loss 110022.0\n",
      "Task_2_loss 107487.0\n",
      "Task_1_loss 102003.0\n",
      "Task_2_loss 105108.0\n",
      "Task_2_loss 102338.0\n",
      "Task_1_loss 99481.8\n",
      "Task_2_loss 100480.0\n",
      "Task_1_loss 96235.9\n",
      "Task_1_loss 94932.6\n",
      "Task_1_loss 92671.4\n",
      "Task_2_loss 97261.9\n",
      "Task_2_loss 93308.5\n",
      "Task_2_loss 91100.7\n",
      "Task_1_loss 89436.6\n",
      "Task_1_loss 89152.4\n",
      "Task_1_loss 86806.1\n",
      "Task_1_loss 85347.5\n",
      "Task_2_loss 89168.3\n",
      "Task_2_loss 85568.7\n",
      "Task_1_loss 81583.2\n",
      "Task_2_loss 84538.0\n",
      "Task_2_loss 79921.9\n",
      "Task_1_loss 80195.1\n",
      "Task_1_loss 77735.7\n",
      "Task_1_loss 76143.4\n",
      "Task_1_loss 73590.8\n",
      "Task_2_loss 77639.7\n",
      "Task_2_loss 76357.2\n",
      "Task_2_loss 77381.2\n",
      "Task_1_loss 72982.9\n",
      "Task_1_loss 68506.5\n",
      "Task_2_loss 72486.3\n",
      "Task_1_loss 67484.7\n",
      "Task_2_loss 70155.0\n",
      "Task_1_loss 65147.4\n",
      "Task_2_loss 68487.0\n",
      "Task_1_loss 63360.6\n",
      "Task_1_loss 62608.5\n",
      "Task_1_loss 61511.1\n",
      "Task_1_loss 62342.5\n",
      "Task_2_loss 62331.4\n",
      "Task_1_loss 58648.7\n",
      "Task_2_loss 62122.1\n",
      "Task_1_loss 57346.3\n",
      "Task_2_loss 59879.9\n",
      "Task_2_loss 58096.0\n",
      "Task_2_loss 58693.5\n",
      "Task_1_loss 54478.2\n",
      "Task_2_loss 57438.5\n",
      "Task_1_loss 53155.2\n",
      "Task_2_loss 55249.3\n",
      "Task_2_loss 53687.4\n",
      "Task_2_loss 54580.8\n",
      "Task_2_loss 55146.1\n",
      "Task_1_loss 49959.5\n",
      "Task_1_loss 51346.2\n",
      "Task_1_loss 48815.9\n",
      "Task_1_loss 50459.1\n",
      "Task_1_loss 48991.7\n",
      "Task_1_loss 48312.4\n",
      "Task_2_loss 49240.4\n",
      "Task_1_loss 46515.8\n",
      "Task_1_loss 45987.2\n",
      "Task_2_loss 48715.2\n",
      "Task_1_loss 44829.7\n",
      "Task_1_loss 43530.4\n",
      "Task_1_loss 41466.2\n",
      "Task_2_loss 44910.3\n",
      "Task_1_loss 41623.4\n",
      "Task_1_loss 41015.2\n",
      "Task_1_loss 41366.1\n",
      "Task_2_loss 44973.9\n",
      "Task_1_loss 39446.6\n",
      "Task_1_loss 38490.0\n",
      "Task_2_loss 40088.7\n",
      "Task_1_loss 36244.9\n",
      "Task_2_loss 42257.9\n",
      "Task_1_loss 34970.7\n",
      "Task_1_loss 35700.9\n",
      "Task_1_loss 34521.2\n",
      "Task_1_loss 34206.2\n",
      "Task_1_loss 34654.6\n",
      "Task_2_loss 34787.5\n",
      "Task_1_loss 32509.2\n",
      "Task_2_loss 34671.3\n",
      "Task_1_loss 32385.3\n",
      "Task_2_loss 33122.5\n",
      "Task_1_loss 32216.1\n",
      "Task_1_loss 31637.6\n",
      "Task_1_loss 32044.7\n",
      "Task_1_loss 30668.5\n",
      "Task_2_loss 33387.3\n",
      "Task_1_loss 28353.2\n",
      "Task_2_loss 31463.7\n",
      "Task_1_loss 29216.4\n",
      "Task_2_loss 31637.8\n",
      "Task_2_loss 32350.7\n",
      "Task_1_loss 27072.4\n",
      "Task_1_loss 27915.3\n",
      "Task_2_loss 30805.0\n",
      "Task_2_loss 30199.8\n",
      "Task_2_loss 29233.0\n",
      "Task_2_loss 28922.9\n",
      "Task_2_loss 29528.9\n",
      "Task_1_loss 26112.6\n",
      "Task_1_loss 25602.5\n",
      "Task_1_loss 24702.8\n",
      "Task_2_loss 27615.9\n",
      "Task_2_loss 28681.9\n",
      "Task_1_loss 25025.4\n",
      "Task_1_loss 24065.1\n",
      "Task_2_loss 27533.2\n",
      "Task_2_loss 27090.5\n",
      "Task_1_loss 23239.7\n",
      "Task_1_loss 23937.6\n",
      "Task_1_loss 23802.3\n",
      "Task_1_loss 23414.1\n",
      "Task_1_loss 23060.2\n",
      "Task_1_loss 22827.3\n",
      "Task_1_loss 22265.3\n",
      "Task_1_loss 21530.7\n",
      "Task_2_loss 24494.8\n",
      "Task_1_loss 21819.8\n",
      "Task_1_loss 21388.9\n",
      "Task_2_loss 21997.9\n",
      "Task_2_loss 22263.7\n",
      "Task_2_loss 23435.9\n",
      "Task_2_loss 22520.1\n",
      "Task_1_loss 19750.3\n",
      "Task_2_loss 21183.7\n",
      "Task_1_loss 19764.2\n",
      "Task_1_loss 19349.0\n",
      "Task_1_loss 19220.9\n",
      "Task_2_loss 21303.5\n",
      "Task_2_loss 20985.7\n",
      "Task_2_loss 21048.0\n",
      "Task_1_loss 18946.0\n",
      "Task_1_loss 18501.9\n",
      "Task_1_loss 18063.6\n",
      "Task_1_loss 18594.4\n",
      "Task_1_loss 18679.6\n",
      "Task_1_loss 18183.2\n",
      "Task_1_loss 17690.5\n",
      "Task_2_loss 19799.3\n",
      "Task_1_loss 17654.2\n",
      "Task_1_loss 16342.9\n",
      "Task_1_loss 16703.0\n",
      "Task_1_loss 15843.4\n",
      "Task_2_loss 18371.2\n",
      "Task_1_loss 16607.2\n",
      "Task_2_loss 18696.3\n",
      "Task_1_loss 15194.0\n",
      "Task_1_loss 15398.2\n",
      "Task_1_loss 15891.9\n",
      "Task_1_loss 15218.0\n",
      "Task_1_loss 15325.2\n",
      "Task_1_loss 15729.3\n",
      "Task_1_loss 15255.1\n",
      "Task_1_loss 14396.1\n",
      "Task_2_loss 16402.2\n",
      "Task_2_loss 16389.8\n",
      "Task_2_loss 16224.3\n",
      "Task_2_loss 16006.2\n",
      "Task_1_loss 13611.6\n",
      "Task_2_loss 15919.7\n",
      "Task_1_loss 14668.1\n",
      "Task_2_loss 14907.9\n",
      "Task_2_loss 15865.2\n",
      "Task_2_loss 14825.7\n",
      "Task_2_loss 15473.7\n",
      "Task_1_loss 13447.4\n",
      "Task_2_loss 14442.1\n",
      "Task_2_loss 14488.7\n",
      "Task_1_loss 13009.8\n",
      "Task_1_loss 12708.6\n",
      "Task_1_loss 12597.5\n",
      "Task_1_loss 11899.1\n",
      "Task_2_loss 14283.0\n",
      "Task_1_loss 12098.9\n",
      "Task_2_loss 13782.6\n",
      "Task_1_loss 11689.3\n",
      "Task_2_loss 13572.2\n",
      "Task_2_loss 12612.2\n",
      "Task_2_loss 12931.6\n",
      "Task_1_loss 11368.1\n",
      "Task_1_loss 10745.2\n",
      "Task_2_loss 12917.0\n",
      "Task_2_loss 12824.0\n",
      "Task_2_loss 12683.1\n",
      "Task_1_loss 10899.0\n",
      "Task_2_loss 11680.7\n",
      "Task_2_loss 11794.8\n",
      "Task_1_loss 10678.7\n",
      "Task_2_loss 12447.2\n",
      "Task_1_loss 10019.7\n",
      "Task_2_loss 11460.9\n",
      "Task_2_loss 11734.1\n",
      "Task_2_loss 11061.9\n",
      "Task_1_loss 10165.1\n",
      "Task_1_loss 9473.3\n",
      "Task_2_loss 10236.0\n",
      "Task_1_loss 10118.5\n",
      "Task_2_loss 10407.5\n",
      "Task_2_loss 10334.8\n",
      "Task_2_loss 10265.6\n",
      "Task_1_loss 8934.85\n",
      "Task_2_loss 10991.2\n",
      "Task_2_loss 9296.1\n",
      "Task_2_loss 10367.7\n",
      "Task_1_loss 8925.96\n",
      "Task_2_loss 10608.4\n",
      "Task_1_loss 9288.54\n",
      "Task_2_loss 9969.69\n",
      "Task_2_loss 10046.0\n",
      "Task_1_loss 8224.64\n",
      "Task_2_loss 9738.39\n",
      "Task_1_loss 7597.74\n",
      "Task_2_loss 9421.17\n",
      "Task_1_loss 8181.81\n",
      "Task_1_loss 7462.16\n",
      "Task_1_loss 8115.13\n",
      "Task_1_loss 8035.01\n",
      "Task_2_loss 8775.59\n",
      "Task_1_loss 7491.61\n",
      "Task_1_loss 7676.3\n",
      "Task_2_loss 9328.78\n",
      "Task_2_loss 8212.2\n",
      "Task_2_loss 8402.53\n",
      "Task_2_loss 7841.12\n",
      "Task_1_loss 7497.67\n",
      "Task_2_loss 8348.55\n",
      "Task_1_loss 7174.72\n",
      "Task_2_loss 7791.33\n",
      "Task_1_loss 7019.51\n",
      "Task_1_loss 7322.72\n",
      "Task_1_loss 6872.28\n",
      "Task_1_loss 6370.73\n",
      "Task_1_loss 6740.22\n",
      "Task_1_loss 6094.37\n",
      "Task_2_loss 8011.57\n",
      "Task_2_loss 7548.98\n",
      "Task_2_loss 7923.87\n",
      "Task_2_loss 7258.24\n",
      "Task_2_loss 7685.15\n",
      "Task_1_loss 6367.67\n",
      "Task_2_loss 7523.01\n",
      "Task_2_loss 6520.37\n",
      "Task_2_loss 6803.25\n",
      "Task_1_loss 6176.37\n",
      "Task_2_loss 6960.57\n",
      "Task_2_loss 6736.23\n",
      "Task_1_loss 5530.76\n",
      "Task_2_loss 6481.06\n",
      "Task_2_loss 6798.92\n",
      "Task_1_loss 6011.9\n",
      "Task_1_loss 5532.15\n",
      "Task_1_loss 4863.12\n",
      "Task_1_loss 5623.18\n",
      "Task_1_loss 5532.14\n",
      "Task_1_loss 5314.94\n",
      "Task_1_loss 5493.24\n",
      "Task_2_loss 6167.19\n",
      "Task_2_loss 6500.29\n",
      "Task_2_loss 5609.21\n",
      "Task_2_loss 5524.65\n",
      "Task_2_loss 5932.25\n",
      "Task_2_loss 5916.5\n",
      "Task_2_loss 5806.94\n",
      "Task_2_loss 5436.33\n",
      "Task_2_loss 5413.92\n",
      "Task_1_loss 4718.09\n",
      "Task_1_loss 4639.35\n",
      "Task_2_loss 5188.49\n",
      "Task_1_loss 4884.22\n",
      "Task_2_loss 5471.61\n",
      "Task_1_loss 4677.38\n",
      "Task_2_loss 5672.7\n",
      "Task_2_loss 5448.24\n",
      "Task_2_loss 5121.17\n",
      "Task_1_loss 4870.6\n",
      "Task_1_loss 3955.77\n",
      "Task_2_loss 4939.42\n",
      "Task_2_loss 4833.01\n",
      "Task_2_loss 5098.81\n",
      "Task_2_loss 5152.33\n",
      "Task_2_loss 5322.83\n",
      "Task_2_loss 5560.96\n",
      "Task_2_loss 4723.57\n",
      "Task_1_loss 4358.06\n",
      "Task_2_loss 4816.94\n",
      "Task_1_loss 4099.75\n",
      "Task_1_loss 4231.55\n",
      "Task_2_loss 4492.91\n",
      "Task_2_loss 4436.58\n",
      "Task_2_loss 4632.77\n",
      "Task_2_loss 3892.88\n",
      "Task_1_loss 3856.36\n",
      "Task_1_loss 3930.42\n",
      "Task_1_loss 3652.53\n",
      "Task_2_loss 3971.4\n",
      "Task_1_loss 3938.8\n",
      "Task_1_loss 3545.07\n",
      "Task_1_loss 3562.87\n",
      "Task_1_loss 3732.61\n",
      "Task_1_loss 3368.01\n",
      "Task_1_loss 3641.62\n",
      "Task_2_loss 3919.85\n",
      "Task_2_loss 4062.95\n",
      "Task_2_loss 4022.42\n",
      "Task_1_loss 3596.55\n",
      "Task_1_loss 3152.39\n",
      "Task_1_loss 3040.44\n",
      "Task_2_loss 3655.31\n",
      "Task_1_loss 2898.21\n",
      "Task_1_loss 3246.91\n",
      "Task_2_loss 3563.83\n",
      "Task_1_loss 3057.4\n",
      "Task_1_loss 3594.67\n",
      "Task_2_loss 3750.24\n",
      "Task_1_loss 3103.38\n",
      "Task_1_loss 3181.92\n",
      "Task_2_loss 3055.49\n",
      "Task_2_loss 3220.24\n",
      "Task_1_loss 2870.11\n",
      "Task_2_loss 3696.56\n",
      "Task_2_loss 3452.18\n",
      "Task_2_loss 3424.9\n",
      "Task_1_loss 2987.39\n",
      "Task_1_loss 2797.53\n",
      "Task_2_loss 3333.19\n",
      "Task_2_loss 3247.36\n",
      "Task_2_loss 3354.66\n",
      "Task_2_loss 2973.85\n",
      "Task_1_loss 2810.87\n",
      "Task_2_loss 3294.67\n",
      "Task_2_loss 2855.86\n",
      "Task_1_loss 2478.24\n",
      "Task_1_loss 2967.9\n",
      "Task_2_loss 2661.81\n",
      "Task_1_loss 2866.44\n",
      "Task_1_loss 2706.59\n",
      "Task_1_loss 2655.94\n",
      "Task_2_loss 3083.59\n",
      "Task_1_loss 3095.49\n",
      "Task_2_loss 2567.58\n",
      "Task_1_loss 2543.77\n",
      "Task_2_loss 2878.88\n",
      "Task_1_loss 2528.48\n",
      "Task_2_loss 3280.88\n",
      "Task_2_loss 2840.83\n",
      "Task_2_loss 2983.76\n",
      "Task_2_loss 2545.74\n",
      "Task_1_loss 2312.94\n",
      "Task_1_loss 2436.34\n",
      "Task_1_loss 2301.26\n",
      "Task_1_loss 2786.64\n",
      "Task_2_loss 2649.51\n",
      "Task_1_loss 2478.35\n",
      "Task_2_loss 2847.41\n",
      "Task_1_loss 2208.09\n",
      "Task_2_loss 2707.09\n",
      "Task_1_loss 2467.59\n",
      "Task_1_loss 2394.29\n",
      "Task_1_loss 2187.67\n",
      "Task_1_loss 2146.2\n",
      "Task_2_loss 2549.44\n",
      "Task_1_loss 2160.29\n",
      "Task_2_loss 2796.61\n",
      "Task_1_loss 2356.68\n",
      "Task_1_loss 2205.19\n",
      "Task_2_loss 2570.59\n",
      "Task_2_loss 2768.48\n",
      "Task_1_loss 2287.07\n",
      "Task_1_loss 2280.69\n",
      "Task_2_loss 2503.2\n",
      "Task_2_loss 2708.66\n",
      "Task_2_loss 2489.18\n",
      "Task_2_loss 2656.28\n",
      "Task_2_loss 2614.11\n",
      "Task_1_loss 2047.14\n",
      "Task_2_loss 2188.99\n",
      "Task_1_loss 2211.62\n",
      "Task_2_loss 2206.29\n",
      "Task_2_loss 2933.14\n",
      "Task_2_loss 2497.75\n",
      "Task_1_loss 1972.54\n",
      "Task_1_loss 1930.12\n",
      "Task_2_loss 2155.53\n",
      "Task_2_loss 2301.07\n",
      "Task_1_loss 2020.2\n",
      "Task_2_loss 2322.74\n",
      "Task_1_loss 2127.69\n",
      "Task_1_loss 1909.74\n",
      "Task_2_loss 2594.96\n",
      "Task_2_loss 1823.91\n",
      "Task_2_loss 2269.56\n",
      "Task_2_loss 2004.3\n",
      "Task_2_loss 2396.07\n",
      "Task_1_loss 1868.95\n",
      "Task_1_loss 1825.87\n",
      "Task_1_loss 1928.16\n",
      "Task_1_loss 2050.35\n",
      "Task_2_loss 2104.06\n",
      "Task_1_loss 2047.63\n",
      "Task_2_loss 2174.87\n",
      "Task_2_loss 2499.14\n",
      "Task_1_loss 1574.62\n",
      "Task_1_loss 1685.13\n",
      "Task_2_loss 1937.07\n",
      "Task_1_loss 1667.87\n",
      "Task_1_loss 1776.11\n",
      "Task_1_loss 2003.83\n",
      "Task_2_loss 1849.24\n",
      "Task_2_loss 2178.79\n",
      "Task_2_loss 1721.2\n",
      "Task_1_loss 1749.8\n",
      "Task_2_loss 2130.24\n",
      "Task_1_loss 1494.28\n",
      "Task_1_loss 1460.16\n",
      "Task_1_loss 1747.23\n",
      "Task_2_loss 2055.94\n",
      "Task_1_loss 1735.85\n",
      "Task_1_loss 1808.58\n",
      "Task_2_loss 1973.9\n",
      "Task_2_loss 2070.84\n",
      "Task_2_loss 1694.99\n",
      "Task_2_loss 2107.8\n",
      "Task_2_loss 1827.89\n",
      "Task_2_loss 1740.67\n",
      "Task_2_loss 1574.53\n",
      "Task_1_loss 1622.37\n",
      "Task_2_loss 1813.92\n",
      "Task_2_loss 1950.37\n",
      "Task_2_loss 1754.41\n",
      "Task_2_loss 1768.58\n",
      "Task_2_loss 1892.05\n",
      "Task_1_loss 1572.35\n",
      "Task_2_loss 1878.64\n",
      "Task_1_loss 1560.2\n",
      "Task_2_loss 1886.08\n",
      "Task_2_loss 1785.55\n",
      "Task_1_loss 1591.62\n",
      "Task_1_loss 1716.95\n",
      "Task_1_loss 1563.92\n",
      "Task_2_loss 1667.55\n",
      "Task_1_loss 1480.59\n",
      "Task_1_loss 1417.55\n",
      "Task_2_loss 1662.31\n",
      "Task_1_loss 1493.49\n",
      "Task_1_loss 1319.91\n",
      "Task_2_loss 1658.95\n",
      "Task_2_loss 1688.09\n",
      "Task_2_loss 1689.72\n",
      "Task_2_loss 1706.73\n",
      "Task_2_loss 1538.98\n",
      "Task_1_loss 1435.31\n",
      "Task_2_loss 1515.72\n",
      "Task_1_loss 1526.16\n",
      "Task_2_loss 1375.25\n",
      "Task_2_loss 1665.08\n",
      "Task_1_loss 1425.44\n",
      "Task_2_loss 1510.95\n",
      "Task_1_loss 1298.95\n",
      "Task_1_loss 1502.41\n",
      "Task_2_loss 1518.57\n",
      "Task_1_loss 1390.94\n",
      "Task_2_loss 1521.58\n",
      "Task_2_loss 1506.98\n",
      "Task_1_loss 1318.79\n",
      "Task_1_loss 1302.22\n",
      "Task_1_loss 1452.63\n",
      "Task_1_loss 1272.95\n",
      "Task_2_loss 1669.81\n",
      "Task_1_loss 1190.12\n",
      "Task_2_loss 1561.18\n",
      "Task_1_loss 1444.62\n",
      "Task_1_loss 1282.12\n",
      "Task_1_loss 1289.91\n",
      "Task_2_loss 1508.81\n",
      "Task_1_loss 1311.45\n",
      "Task_2_loss 1417.85\n",
      "Task_2_loss 1392.81\n",
      "Task_2_loss 1336.54\n",
      "Task_2_loss 1159.02\n",
      "Task_1_loss 1147.54\n",
      "Task_1_loss 1416.08\n",
      "Task_2_loss 1466.87\n",
      "Task_1_loss 1206.15\n",
      "Task_2_loss 1419.39\n",
      "Task_1_loss 1180.89\n",
      "Task_1_loss 1297.52\n",
      "Task_1_loss 1186.04\n",
      "Task_2_loss 1530.05\n",
      "Task_2_loss 1397.9\n",
      "Task_1_loss 1289.76\n",
      "Task_2_loss 1236.37\n",
      "Task_2_loss 1540.16\n",
      "Task_2_loss 1415.32\n",
      "Task_2_loss 1599.27\n",
      "Task_2_loss 1639.87\n",
      "Task_1_loss 1280.97\n",
      "Task_2_loss 1406.88\n",
      "Task_2_loss 1629.37\n",
      "Task_1_loss 1331.08\n",
      "Task_1_loss 1048.29\n",
      "Task_2_loss 1763.43\n",
      "Task_2_loss 1260.56\n",
      "Task_2_loss 1526.11\n",
      "Task_2_loss 1418.99\n",
      "Task_2_loss 1475.39\n",
      "Task_2_loss 1315.22\n",
      "Task_2_loss 1267.48\n",
      "Task_1_loss 1204.21\n",
      "Task_1_loss 1253.85\n",
      "Task_2_loss 1360.89\n",
      "Task_2_loss 1600.19\n",
      "Task_2_loss 1338.67\n",
      "Task_1_loss 1315.47\n",
      "Task_2_loss 1335.79\n",
      "Task_1_loss 1205.63\n",
      "Task_1_loss 1018.15\n",
      "Task_1_loss 1367.77\n",
      "Task_2_loss 1472.96\n",
      "Task_1_loss 1290.31\n",
      "Task_2_loss 1389.18\n",
      "Task_1_loss 1253.76\n",
      "Task_2_loss 1332.64\n",
      "Task_1_loss 1218.15\n",
      "Task_1_loss 1174.49\n",
      "Task_1_loss 1240.87\n",
      "Task_2_loss 1371.25\n",
      "Task_2_loss 1132.3\n",
      "Task_2_loss 1427.42\n",
      "Task_2_loss 1189.67\n",
      "Task_1_loss 1228.12\n",
      "Task_1_loss 1185.01\n",
      "Task_1_loss 1058.78\n",
      "Task_2_loss 1416.47\n",
      "Task_2_loss 1297.74\n",
      "Task_2_loss 1275.19\n",
      "Task_2_loss 1145.58\n",
      "Task_2_loss 1408.31\n",
      "Task_1_loss 1065.69\n",
      "Task_1_loss 1017.05\n",
      "Task_2_loss 1315.12\n",
      "Task_2_loss 1107.48\n",
      "Task_1_loss 1119.56\n",
      "Task_2_loss 1296.95\n",
      "Task_1_loss 1151.63\n",
      "Task_1_loss 1099.81\n",
      "Task_1_loss 1008.52\n",
      "Task_2_loss 1163.4\n",
      "Task_2_loss 1150.0\n",
      "Task_2_loss 1147.93\n",
      "Task_1_loss 992.508\n",
      "Task_1_loss 1259.64\n",
      "Task_2_loss 1163.83\n",
      "Task_1_loss 1118.5\n",
      "Task_1_loss 1048.11\n",
      "Task_2_loss 1036.76\n",
      "Task_2_loss 1205.62\n",
      "Task_2_loss 1200.87\n",
      "Task_1_loss 1027.97\n",
      "Task_2_loss 1251.91\n",
      "Task_1_loss 890.955\n",
      "Task_2_loss 984.018\n",
      "Task_2_loss 1347.83\n",
      "Task_2_loss 1223.15\n",
      "Task_2_loss 1034.45\n",
      "Task_2_loss 1109.24\n",
      "Task_1_loss 1026.06\n",
      "Task_1_loss 1022.3\n",
      "Task_1_loss 1188.52\n",
      "Task_1_loss 1068.14\n",
      "Task_2_loss 1151.52\n",
      "Task_1_loss 1110.52\n",
      "Task_2_loss 1048.23\n",
      "Task_2_loss 1061.22\n",
      "Task_2_loss 1064.7\n",
      "Task_2_loss 1130.0\n",
      "Task_1_loss 1148.91\n",
      "Task_1_loss 955.501\n",
      "Task_1_loss 982.068\n",
      "Task_1_loss 1016.74\n",
      "Task_2_loss 995.813\n",
      "Task_2_loss 1215.04\n",
      "Task_1_loss 909.81\n",
      "Task_1_loss 964.936\n",
      "Task_1_loss 976.771\n",
      "Task_2_loss 1159.97\n",
      "Task_2_loss 1059.44\n",
      "Task_1_loss 840.972\n",
      "Task_1_loss 946.93\n",
      "Task_2_loss 1127.6\n",
      "Task_2_loss 1216.9\n",
      "Task_2_loss 1124.33\n",
      "Task_1_loss 1048.57\n",
      "Task_1_loss 950.504\n",
      "Task_1_loss 993.012\n",
      "Task_2_loss 1038.44\n",
      "Task_1_loss 892.619\n",
      "Task_1_loss 1065.6\n",
      "Task_1_loss 1054.8\n",
      "Task_2_loss 1038.5\n",
      "Task_2_loss 1074.02\n",
      "Task_1_loss 938.291\n",
      "Task_2_loss 1181.19\n",
      "Task_1_loss 986.089\n",
      "Task_1_loss 924.574\n",
      "Task_2_loss 1001.2\n",
      "Task_1_loss 954.091\n",
      "Task_1_loss 917.497\n",
      "Task_1_loss 910.495\n",
      "Task_1_loss 1021.07\n",
      "Task_2_loss 887.419\n",
      "Task_2_loss 1053.15\n",
      "Task_1_loss 1020.95\n",
      "Task_1_loss 1087.66\n",
      "Task_2_loss 1018.5\n",
      "Task_1_loss 893.966\n",
      "Task_1_loss 1010.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task_1_loss 1077.05\n",
      "Task_2_loss 1200.01\n",
      "Task_3_loss 176039.0\n"
     ]
    }
   ],
   "source": [
    "# Calculation (Session) Code\n",
    "# ==========================\n",
    "\n",
    "# open the session\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    for iters in range(1000):\n",
    "        choice=random.choice(['Task_1','Task_2','Task_3'])\n",
    "        if choice=='Task_1':\n",
    "            _, Task_1_loss = session.run([Task_1_op, Task_1_Loss],\n",
    "                            {\n",
    "                              data: np.random.rand(10,10)*10,\n",
    "                              Task_1_labels: np.random.rand(10,20)*10,\n",
    "                              Task_2_labels: np.random.rand(10,20)*10,\n",
    "                              Task_3_labels: np.random.rand(10,20)*10\n",
    "\n",
    "                              })\n",
    "            print('Task_1_loss',Task_1_loss)\n",
    "        elif choice=='Task_2':\n",
    "            _, Task_2_loss = session.run([Task_2_op, Task_2_Loss],\n",
    "                            {\n",
    "                              data: np.random.rand(10,10)*10,\n",
    "                              Task_1_labels: np.random.rand(10,20)*10,\n",
    "                              Task_2_labels: np.random.rand(10,20)*10,\n",
    "                              Task_3_labels: np.random.rand(10,20)*10\n",
    "                              })\n",
    "            print('Task_2_loss',Task_2_loss)\n",
    "        else:\n",
    "            _, Task_3_loss = session.run([Task_3_op, Task_3_Loss],\n",
    "                {\n",
    "                  data: np.random.rand(10,10)*10,\n",
    "                  Task_1_labels: np.random.rand(10,20)*10,\n",
    "                  Task_2_labels: np.random.rand(10,20)*10,\n",
    "                  Task_3_labels: np.random.rand(10,20)*10\n",
    "                  })\n",
    "print('Task_3_loss',Task_3_loss)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
